{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"techsash/waste-classification-data\")\n",
        "print(\"Path to datasetÂ files:\", path)"
      ],
      "metadata": {
        "id": "agVxTfXjfnyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up paths to the train and test directories\n",
        "train_dir = r\"/root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1/DATASET/TRAIN\"\n",
        "test_dir = r\"/root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1/DATASET/TEST\"\n",
        "\n",
        "# Use ImageDataGenerator to prepare the data for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Display sample images from each class\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(4):  # Display 4 images (2 from each class if available)\n",
        "    image, label = next(train_data)  # Use next() to get a batch of images\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.imshow(image[0])  # Display the first image in the batch\n",
        "    plt.title(\"Class: \" + (\"Organic\" if label[0] == 0 else \"Recyclable\"))\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Sample Images from Each Class\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0uIqsAmvfu8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#include_top=False: Excludes the fully connected layers at the top of MobileNetV2\n",
        "#weights='imagenet': Uses pre-trained weights from the ImageNet dataset\n",
        "mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freezes all the layers in the pre-trained MobileNetV2 to ensures that only the custom layers willlearn from new data\n",
        "mobilenet_model.trainable = False\n",
        "\n",
        "# Add custom layers for classification\n",
        "model = tf.keras.Sequential([\n",
        "    mobilenet_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(), #reduces the spatial dimensions of single vector(summation of matrix)\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# We start with a pre-trained MobileNet model, adding layers to classify waste images into O or R.\n"
      ],
      "metadata": {
        "id": "NsiJlVxvjPCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data,\n",
        "    epochs=2\n",
        ")\n",
        "\n",
        "# After training the model, save it to a file\n",
        "model.save('mobilenet_waste_classifier.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# The model learns over 5 epochs, seeing images in the training data, adjusting itself, and testing on new images."
      ],
      "metadata": {
        "id": "dD9M5oDqjO_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_prob = model.predict(test_data).flatten()\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "y_true = test_data.classes  # True labels from test data\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=['Organic', 'Recyclable']))\n",
        "\n",
        "# Print confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Here, we measure the performance of the model."
      ],
      "metadata": {
        "id": "Aw2JU7LBtTub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save(\"ffd_model.h5\")"
      ],
      "metadata": {
        "id": "AY0p7R_Lza_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Yy6JVRcIiD"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "\n",
        "from PIL import Image, ImageTk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"ffd_model.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Function to load and predict an image\n",
        "def predict_image(img):\n",
        "  \"\"\"Predicts whether an image contains wildfire or not.\n",
        "\n",
        "  Args:\n",
        "    img: The input image.\n",
        "\n",
        "  Returns:\n",
        "    A string indicating the prediction (\"Wildfire\" or \"No Wildfire\").\n",
        "  \"\"\"\n",
        "\n",
        "  img = img.resize((224, 224))\n",
        "  img_array = np.array(img) / 255.0  # Rescale like during training\n",
        "  img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "  prediction = model.predict(img_array)[0][0]  # Extracts the scalar prediction value\n",
        "  result = \"Organic\" if prediction < 0.5 else \"Non Organic\"\n",
        "  return result\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type=\"pil\"),  # Input type is PIL Image\n",
        "    outputs=\"text\",\n",
        "    title=\"Organic or Non Organic Waste Detector\",\n",
        "    description=\"Upload an image to predict whether it organic or not.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "hHwI1FBRx2C-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}